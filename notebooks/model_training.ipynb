{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Model Training \n",
    "Run the cells to reproduce the results\n",
    "\n",
    "### Data and Models Used in Hisia\n",
    "\n",
    "**Data:** 2016 TrustPilot's 254,464 Danish reviews' body and stars and [8 fake reviews]*20 see notes for the explanation.<br>\n",
    "&ensp; _Update_: 2021-10-02: Political Data from [Sentiment Analysis on Comments from Danish Political Articles on Social Media](https://github.com/steffan267/Sentiment-Analysis-on-Danish-Social-Media)\n",
    "\n",
    "**Models**<br>\n",
    "Hisia, _LogisticRegression_ with SAGA, a variant of Stochastic Average Gradient (SAG), as a solver. L2 penalty was select for the base model. Test score **accuracy is ca. 93%** and **recall of 93%**. SAGA is a faster solver for large datasets (both rows and columns wise). As a stochastic gradient, the memory of the previous gradient is incorporated/feed-forward to achieve faster convergence rate. Seeds of 42 was set in data split, and 42 in a model for reproducibility.\n",
    "\n",
    "HisiaTrain, _SGDClassifier_, Stochastic Gradient Descent learner with smooth loss 'modified_huber as loss function and L2 penalty. Test score **accurance  94%** and **recall of 94%**. SGDClassifier was select because of partial_fit. It allows batch/online training.\n",
    "\n",
    "**Note:** This score reflects models in regards to TrustPilot reviews style of writing.<b>\n",
    " >8*10 fake reviews. TrustPilot reviews are directed toward products and services. Words like 'elsker'(love) or 'hader'(hate) are rarely used. To make sure the model learns such a relationship, I added 8 reviews and duplicated them 10 times. These new sentences did not increase or decrease the model accurance but added the correct coefficient of love, hate and (ikke d√•rligt) not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Author Prayson W. Daniel\n",
      "\n",
      "Last updated: 2022-10-27T14:17:02.311225+02:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.6\n",
      "IPython version      : 8.5.0\n",
      "\n",
      "pandas      : 1.5.1\n",
      "numpy       : 1.23.4\n",
      "matplotlib  : 3.6.1\n",
      "scikit-learn: 1.0.2\n",
      "lemmy       : 2.1.0\n",
      "dill        : 0.3.4\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.0-52-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext watermark\n",
    "%watermark -uniz --author \"Author Prayson W. Daniel\" -vm -p pandas,numpy,matplotlib,scikit-learn,lemmy,dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pwd/Codes/hisia\n"
     ]
    }
   ],
   "source": [
    "# run outside notebook\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import joblib\n",
    "import re\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import dill\n",
    "import lemmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.utils._testing import ignore_warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hisia.models.helpers import logger, config\n",
    "from hisia.reports.visualization import show_diagram\n",
    "from hisia.metrics.performance import classification_report\n",
    "from hisia.reports.visualization import show_most_informative_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stops were custom made from both unknown Danish stops words and products and services related words such as delivery, package, post office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = joblib.load(config[\"data\"][\"stop_words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer separates emojis from the words, removes digits, repetive words and stop words and lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = lemmy.load('da')\n",
    "\n",
    "\n",
    "# Add more stopwords\n",
    "STOP_WORDS.update({\"kilometer\", \"alme\", \"bank\", \"brand\", \"dansk\", \"presi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"kilometer\" in STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(blob, stop_words=STOP_WORDS, remove_digits=True):\n",
    "    \n",
    "    if stop_words is None:\n",
    "        stop_words = {}\n",
    "    \n",
    "    blob = blob.lower()\n",
    "    \n",
    "     # eyes [nose] mouth | mouth [nose] eyes pattern\n",
    "    emoticons = r\"(?:[<>]?[:;=8][\\-o\\*\\']?[\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\]|[\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\][\\-o\\*\\']?[:;=8][<>]?)\"\n",
    "    emoticon_re = re.compile(emoticons, re.VERBOSE | re.I | re.UNICODE)\n",
    "    \n",
    "    text = re.sub(r'[\\W]+', ' ', blob)\n",
    "    \n",
    "    # remove 3+ repetitive characters i.e. hellllo -> hello, jaaaa -> jaa \n",
    "    repetitions = re.compile(r'(.)\\1{2,}')\n",
    "    text = repetitions.sub(r'\\1\\1', text)\n",
    "    \n",
    "    # remove 2+ repetitive words e.g. hej hej hej -> hej\n",
    "    \n",
    "    repetitions = re.compile(r'\\b(\\w+)\\s+(\\1\\s*)+\\b')\n",
    "    text = repetitions.sub(r'\\1 ', text)\n",
    "    \n",
    "    \n",
    "    # 14√•r --> 14 √•r\n",
    "    text = re.sub(r'([0-9]+(\\.[0-9]+)?)', r' \\1 ', text).strip()\n",
    "    \n",
    "    emoji = ''.join(re.findall(emoticon_re, blob))\n",
    "    \n",
    "       \n",
    "    # remove stopwords\n",
    "    text_nostop = [word for word in text.split() if word not in stop_words]\n",
    "    \n",
    "    # tokenization lemmatize\n",
    "    lemmatized_text = [lemmatizer.lemmatize('', word)[-1]  \n",
    "                                 for word in text_nostop]\n",
    "    \n",
    "    remove_stopwords = ' '.join(word for word in lemmatized_text if len(word)>1)\n",
    "    \n",
    "    if remove_digits:\n",
    "        remove_stopwords = re.sub(r'\\b\\d+\\b', '', remove_stopwords)\n",
    "    \n",
    "\n",
    "    # remove extra spaces\n",
    "    remove_stopwords = ' '.join(remove_stopwords .split())\n",
    "    result = f'{remove_stopwords} {emoji}'.encode('utf-8').decode('utf-8')\n",
    "       \n",
    "    \n",
    "    return result.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vred', 'ikke', ':(']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Jeg er vred p√•, at jeg ikke fik min pakke :( kilometer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(config[\"data\"][\"data_trustpilot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake reviews to teach our model the missing relationsh that is not found in TP reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.DataFrame([('men elsker elsker', 1,5), \n",
    "                   ('elsker det ikke', 0, 1), \n",
    "                   ('ikke d√•rligt', 1, 5),\n",
    "                   ('elsker skat, k√¶reste, tilbedte, dyrebare, elskling, darling, hjerte, hjertensk√¶r; ven; veninde', 1, 5),\n",
    "                   ('d√•rlig: syg, sl√∏j, utilpas, ilde tilpas, upasselig, snavs, indisponeret;'\n",
    "                    'sygelig, usund, ond, slet; arg, uheldig, umulig, elendig, under al kritik,'\n",
    "                    'd√∏dssyg, skidt, skral, krank, ussel, ikke noget at samle p√•, talentl√∏s, uantagelig,'\n",
    "                    'uacceptabel, forkastelig; ikke noget at r√•be hurra for, ikke noget at skrive hjem om,'\n",
    "                    'noget skidt (lort, pis), andenklasses, tredjeklasses (osv.), ringe, halvgod, ikke nogen'\n",
    "                    '√∏rn til, ikke ens st√¶rke side, ens svage punkt, som en br√¶kket arm; sjusket; ufordelagtig,'\n",
    "                    'ufyldestg√∏rende, utilstr√¶kkelig, utilfredsstillende, middelm√•dig, under lavm√•let, uduelig,'\n",
    "                    'udygtig, uhensigtsm√¶ssig, forkert, tarvelig; skadelig, √∏del√¶ggende, ford√¶rvet, ubrugelig;'\n",
    "                    'ubehagelig, v√¶mmelig, ulystbetonet; dys-; utiltalende, usympatisk, kedelig', 0, 1),\n",
    "                    ('20.000 kroner. Det er, hvad man som arbejdstager burde f√• ekstra i l√∏nningsposen,'\n",
    "                    ' hvis man skal kunne acceptere at have en d√•rlig chef.', 0,1),\n",
    "                   ('k√¶rlighed, hvordan elsker vi hinanden godt ‚Äì uanset hvem vi elsker?',1,5),\n",
    "                   ('jeg hader dig', 0, 1),\n",
    "                   \n",
    "                  ]*20, \n",
    "                  columns='features target stars'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New data from [\"Sentiment Analysis on Comments from Danish Political Articles on Social Media\"](https://github.com/lucaspuvis/SAM/blob/master/Thesis.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAM = \"https://raw.githubusercontent.com/steffan267/Sentiment-Analysis-on-Danish-Social-Media/master/all_sentences.csv\"\n",
    "ds = pd.read_csv(SAM, names=[\"target\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    4087\n",
       "-1    2610\n",
       " 1    1007\n",
       "-2     862\n",
       " 2     442\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_json(config[\"data\"][\"data_steffan267\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>3472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          observations\n",
       "target                \n",
       "negative          3472\n",
       "positive          1449"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    ds\n",
    "      .loc[lambda d: d['target'].ne(0), [\"target\", ]]\n",
    "      .assign(target= lambda d: np.where(d[\"target\"].gt(0), 1, 0))\n",
    "      .value_counts()\n",
    "      .rename(index ={0: \"negative\", 1:\"positive\"})\n",
    "      .to_frame(name=\"observations\")    \n",
    ")\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = (\n",
    "    ds\n",
    "      .loc[lambda d: d[\"target\"].ne(0), [\"features\", \"target\"]]\n",
    "      .assign(target= lambda d: np.where(d[\"target\"].gt(0), 1, 0))\n",
    "       \n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.concat([dt, ds], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt.to_json('../data/data_custom.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['features'], \n",
    "                                                     df['target'],\n",
    "                                                     test_size=config[\"train\"][\"test_size\"],\n",
    "                                                     random_state=config[\"base\"][\"random_state\"],\n",
    "                                                     stratify=df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = (pd.concat([X_train, dt['features']] ,ignore_index=True),\n",
    "                    pd.concat([y_train, dt['target']] ,ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing Size: 208652\n",
      "Test Size:    50893\n",
      "\n",
      "Traing Size\n",
      "\tPositive||Negative Samples\n",
      "\t  103315||105337\n",
      "\n",
      "Test Size\n",
      "\tPositive||Negative Samples\n",
      "\t  25446||25447\n"
     ]
    }
   ],
   "source": [
    "print(f'Traing Size: {X_train.shape[0]}\\nTest Size: {X_test.shape[0]:>8}')\n",
    "print(f'\\nTraing Size\\n\\tPositive||Negative Samples\\n\\t  {y_train[y_train==1].shape[0]}||{y_train[y_train==0].shape[0]}')\n",
    "print(f'\\nTest Size\\n\\tPositive||Negative Samples\\n\\t  {y_test[y_test==1].shape[0]}||{y_test[y_test==0].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia = Pipeline(steps =[\n",
    "        ('count_vectorizer',  CountVectorizer(ngram_range=(1, 2), \n",
    "                                 max_features=config[\"train\"][\"vectorizer_max_features\"],\n",
    "                                 tokenizer=tokenizer, \n",
    "                                 stop_words=STOP_WORDS\n",
    "                                )\n",
    "        ),\n",
    "        ('feature_selector', SelectKBest(chi2, k=config[\"train\"][\"select_k_best\"])),\n",
    "        ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "        ('logistic_regression', LogisticRegressionCV(cv=5,\n",
    "                                                    solver=config[\"train\"][\"lr_solver\"],\n",
    "                                                    scoring=config[\"train\"][\"lr_scoring\"],\n",
    "                                                    max_iter=config[\"train\"][\"lr_max_iter\"],\n",
    "                                                    n_jobs=-1,\n",
    "                                                    random_state=config[\"base\"][\"random_state\"],\n",
    "                                                    verbose=config[\"train\"][\"lr_verbose\"]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 46s, sys: 1.17 s, total: 3min 47s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with ignore_warnings(): # ConvergenceWarning\n",
    "    hisia.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9227988131963138"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hisia.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hisia.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': ' 0.923', 'recall': ' 0.923', 'f1': ' 0.923'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_diagram(hisia, X_train, y_train, X_test, y_test, compare_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = hisia.named_steps['count_verctorizer'].get_feature_names_out()\n",
    "best_features = [feature_names[i] for i in hisia.named_steps['feature_selector'].get_support(indices=True)]\n",
    "predictor =  hisia.named_steps['logistic_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "print(f'Showing {N} models learned features for negative and postive decisions')\n",
    "print('_'*70)\n",
    "print('\\n')\n",
    "show_most_informative_features(best_features, predictor, n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [negative, positive] probability\n",
    "hisia.predict_proba(['det er ikke okay!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia.predict_proba(['det er ikke d√•rligt!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hisia.predict_proba(['jeg kan lide det!']), \n",
    " hisia.predict_proba(['jeg kan ikke lide det!']),\n",
    " hisia.predict_proba(['jeg elsker det!']),\n",
    " hisia.predict_proba(['jeg elsker det slet ikke!'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_max = ['Jeg er vred p√•, at jeg ikke fik min pakke :( elsker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia.named_steps['logistic_regression'].random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia.predict_proba(['']) # model is positive :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia.predict(mad_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = hisia.predict_proba(mad_max)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia.decision_function(mad_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = hisia.named_steps['count_verctorizer'].transform(mad_max)\n",
    "v = hisia.named_steps['feature_selector'].transform(v)\n",
    "v = pd.DataFrame.sparse.from_spmatrix(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = set(v.T.loc[v.eq(1).values[0]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_up = {index:(token,coef) for index, coef, token in \n",
    "           zip(range(len(best_features)),\n",
    "               hisia.named_steps['logistic_regression'].coef_[0], \n",
    "               best_features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{look_up[item] for item in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia.named_steps['logistic_regression'].intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = [look_up[item] for item in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(i for _, i in g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ùëì(ùê±): ùëù(ùê±) = 1 / (1 + exp(‚àíùëì(ùê±))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(1 + np.exp(-(sum(i for _, i in g) + hisia.named_steps['logistic_regression'].intercept_[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia.decision_function(mad_max)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = np.where(df[0] > .5, 'negative', 'positive')\n",
    "\n",
    "df.columns = ['negative_probability','positive_probability','sentiment']\n",
    "\n",
    "Sentiment = namedtuple('Sentiment', ['sentiment','positive_probability', 'negative_probability'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Sentiment(**df.round(3).to_dict(orient='index')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrainable Model SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisia_trainer =Pipeline(steps =[\n",
    "                ('count_verctorizer',  CountVectorizer(ngram_range=(1, 2), \n",
    "                                         max_features=100000,\n",
    "                                         tokenizer=tokenizer, \n",
    "                                        )\n",
    "                ),\n",
    "                ('feature_selector', SelectKBest(chi2, k=5000)),\n",
    "                ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "                ('modified_hubern', SGDClassifier(loss='modified_huber', \n",
    "                                                      random_state=7,\n",
    "                                                      max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hisia_trainer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for partil_fit we have to split the pipeline to transformation and scoring\n",
    "hisia_trainer.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_diagram(hisia_trainer, X_train, y_train, X_test, y_test, compare_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = hisia_trainer.named_steps['count_verctorizer'].get_feature_names()\n",
    "best_features = [feature_names[i] for i in hisia_trainer.named_steps['feature_selector'].get_support(indices=True)]\n",
    "predictor =  hisia_trainer.named_steps['modified_hubern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "print(f'Showing {N} models learned features for negative and postive decisions')\n",
    "print('_'*70)\n",
    "print('\\n')\n",
    "show_most_informative_features(best_features, predictor, n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hisia",
   "language": "python",
   "name": "hisia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "67b08ac9a0993e0f0aef94da8685d7212f0b41c0b425d6d6e8b344602287b3f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
